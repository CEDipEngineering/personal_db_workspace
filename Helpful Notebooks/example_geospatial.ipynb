{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec0c9302-7561-480e-aae7-b2c2fa3e4a1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook Summary\n",
    "\n",
    "This notebook demonstrates how to create a sample Spark DataFrame containing WKT (Well-Known Text) geometries and perform spatial queries using Databricks SQL spatial functions. The workflow includes:\n",
    "\n",
    "- Creating a DataFrame with point geometries in WKT format.\n",
    "- Registering the DataFrame as a temporary SQL view.\n",
    "- Defining a polygon in WKT format for spatial filtering.\n",
    "- Using spatial SQL functions (`ST_Within`, `ST_Distance`, `ST_GeomFromWKT`) to:\n",
    "  - Filter points within the polygon.\n",
    "  - Calculate the distance of each point from the origin.\n",
    "\n",
    "**Note:**  \n",
    "Spatial SQL functions require Databricks Runtime 17.1 (Beta) or later. (Photon is optional)\n",
    "\n",
    "Documentation:\n",
    "\n",
    "- [Medium Overview](https://medium.com/towards-data-engineering/databricks-spatial-sql-is-here-a-game-changer-for-geospatial-intelligence-on-the-lakehouse-e7b1e5eb50ba)\n",
    "- [Mosaic Spatial SQL](https://databrickslabs.github.io/mosaic/api/spatial-functions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d99ad372-7a32-406a-b4f7-39df042a23d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a sample DataFrame with WKT geometries\n",
    "data = [\n",
    "    (i, f\"POINT({i} {i})\") for i in range(10)\n",
    "]\n",
    "columns = [\"id\", \"wkt\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Register as a temp view\n",
    "df.createOrReplaceTempView(\"points\")\n",
    "\n",
    "# Create a polygon for spatial queries\n",
    "polygon_wkt = \"POLYGON((0 0, 0 5, 5 5, 5 0, 0 0))\"\n",
    "\n",
    "# Use Spatial SQL functions to filter points within the polygon\n",
    "result = spark.sql(f\"\"\"\n",
    "SELECT\n",
    "  id,\n",
    "  wkt,\n",
    "  ST_Within(ST_GeomFromWKT(wkt), ST_GeomFromWKT('{polygon_wkt}')) AS within_polygon,\n",
    "  ST_Distance(ST_GeomFromWKT(wkt), ST_GeomFromWKT('POINT(0 0)')) AS distance_from_origin\n",
    "FROM points\n",
    "\"\"\")\n",
    "\n",
    "display(result)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "example_geospatial",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
